---
title: "5. The Forecaster's Toolbox.RMD"
author: "Russ Conte"
date: "10/4/2021"
output: html_document
---

# 5.1 A tidy forecasting workflow

![](5. Tidy_forecasting_workflow.jpg)

## Data preparation (tidy)

We will model GDP per capita over time; so first, we must compute the relevant variable.

```{r}
library(tidyverse)
library(fpp3)
gdppc <- global_economy %>% 
  mutate(GDP_per_capita = GDP / Population)
gdppc

```

## Plot the data (visualize), we will use Sweden as our example

```{r Plot the data for Sweden}
gdppc %>% 
  filter(Country == "Sweden") %>% 
  autoplot(GDP_per_capita) +
  labs( y = "$US", title = "GDP per capita for Sweden")

TSLM(GDP_per_capita ~ trend())
```

## Definte a model (specify)
There are many different time series models that can be used for forecasting, and much of this book is dedicated to describing various models. Specifying an appropriate model for the data is essential for producing appropriate forecasts. For example, a linear trend model (to be discussed in Chapter 7) for GDP per capita can be specified with:

```{r Define the model}
TSLM(GSP_per_capita ~ trend())
```

## Train the model
Once an appropriate model is specified, we next train the model on some data. One or more model specifications can be estimated using the model() function.

To estimate the model in our example, we use

```{r Train the model}
fit <- gdppc %>%
   model(trend_model = TSLM(GDP_per_capita ~ trend()))
fit
```

This fits a linear trend model to the GDP per capita data for each combination of key variables in the tsibble. In this example, it will fit a model to each of the 263 countries in the dataset. The resulting object is a model table or a “mable.”


## Check model performance

Once a model has been fitted, it is important to check how well it has performed on the data. There are several diagnostic tools available to check model behaviour, and also accuracy measures that allow one model to be compared against another.

## Produce forecasts (forecast)

With an appropriate model specified, estimated and checked, it is time to produce the forecasts using `forecast()`. The easiest way to use this function is by specifying the number of future observations to forecast. For example, forecasts for the next 10 observations can be generated using `h = 10`. We can also use natural language; e.g., `h = "2 years"` can be used to predict two years into the future.

```{r Forecast 3 years into the future}

fit %>% forecast(h = "3 years")
fit

```


This is a forecast table, or “fable.” Each row corresponds to one forecast period for each country. The `GDP_per_capita` column contains the forecast distribution, while the .mean column contains the point forecast. The point forecast is the mean (or average) of the forecast distribution.

The forecasts can be plotted along with the historical data using `autoplot()` as follows:

```{r Figure 5.2: Forecasts of GDP per capita for Sweden using a simple trend model. }
fit %>% 
  forecast(h = "3 years") %>% 
  filter(Country == "Sweden") %>% 
  autoplot(gdppc) +
  labs(y = "$US", title = "GDP per capita for Sweden")
```

# 5.1 Some simple forecasting methods

We will use four simple forecasting methodsas benchmarks throughout this book. To illustrate them, we will use quarterly Australian clay brick production between 1970 and 2004:

```{r Clay brick production}
# bricks <- aus_production %>% 
#   filter_index("1970 Q1" ~ "2004 Q4")

bricks <- aus_production %>%
  filter_index("1970 Q1" ~ "2004 Q4")

```

The `filter_index()` function is a convenient shorthand for extracting a section of a time series.

## Mean method

Here, the forecasts of all future values are equal to the average (or “mean”) of the historical data. If we let the historical data be denoted by y1,…,yT, then we can write the forecasts as

$$\hat{y}_{T+h|T}=\bar{y}=(y_1 + ... +y_T)/T$$

```{r Figure 5.3: Mean (or average) forecasts applied to clay brick production in Australia. }

train <- aus_production %>%
  filter_index("1970 Q1" ~ "2004 Q4")
# Fit the models
bricks_fit <- train %>%
  model(
    Mean = MEAN(Bricks),
  )
# Generate forecasts for 23 quarters
bricks_fc <- bricks_fit %>% forecast(h = 23)
# Plot forecasts against actual values
bricks_fc %>%
  autoplot(train, level = NULL) +
  labs(
    y = "Bricks in thousands ('000)",
    title = "Forecasts for quarterly brick production"
  ) +
  guides(colour = guide_legend(title = "Forecast"))


```


## Naïve method

For naïve forecasts, we simply set all forecasts to be the value of the last observation. That is,

$$\hat{y}_{T+h|T}=y_T$$

<b>This method works remarkably well for many economic and financial time series.</b>

```{r Figure 5.4: Naïve forecasts applied to clay brick production in Australia. }

train <- aus_production %>%
  filter_index("1970 Q1" ~ "2004 Q4")
# Fit the models
bricks_fit <- train %>%
  model(
    naive = NAIVE(Bricks),
  )
# Generate forecasts for 23 quarters
bricks_fc <- bricks_fit %>% forecast(h = 23)
# Plot forecasts against actual values
bricks_fc %>%
  autoplot(train, level = NULL) +
  labs(
    y = "Bricks in thousands ('000)",
    title = "Forecasts for quarterly brick production"
  ) +
  guides(colour = guide_legend(title = "Forecast"))



```

## Seasonal naïve method

A similar method is useful for highly seasonal data. In this case, we set each forecast to be equal to the last observed value from the same season of the year (e.g., the same month of the previous year). Formally, the forecast for time T+h is written as

$$\hat{y}_{T+h|T}=y_{T+h-m(k+1)}$$

where m= the seasonal period, and k is the integer part of (h−1)/m (i.e., the number of complete years in the forecast period prior to time T+h).

```{r Figure 5.5: Seasonal naïve forecasts applied to clay brick production in Australia.}

train <- aus_production %>%
  filter_index("1970 Q1" ~ "2004 Q4")
# Fit the models
bricks_fit <- train %>%
  model(
    snaive = SNAIVE(Bricks),
  )
# Generate forecasts for 23 quarters
bricks_fc <- bricks_fit %>% forecast(h = 23)
# Plot forecasts against actual values
bricks_fc %>%
  autoplot(train, level = NULL) +
  labs(
    y = "Bricks in thousands ('000)",
    title = "Forecasts for quarterly brick production"
  ) +
  guides(colour = guide_legend(title = "Forecast"))

```

## Drift method

A variation on the naïve method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the <b>drift</b>) is set to be the average change seen in the historical data. Thus the forecast for time T+h is given by

$$\hat{y}_{T+h|T}=y_T + \frac{h}{T-1}\sum_{t=2}^T(y_t - y_{t-1}) = y_T + h\left( \frac{y_t - y_1}{T-1} \right)$$

This is equivalent to drawing a line between the first and last observations, and extrapolating it into the future.

```{r}
train <- aus_production %>%
  filter_index("1970 Q1" ~ "2004 Q4")
# Fit the models
bricks_fit <- train %>%
  model(
    RW(Bricks ~ drift()),
  )
# Generate forecasts for 23 quarters
bricks_fc <- bricks_fit %>% forecast(h = 23)
# Plot forecasts against actual values
bricks_fc %>%
  autoplot(train, level = NULL) +
  labs(
    y = "Bricks in thousands ('000)",
    title = "Forecasts for quarterly brick production"
  ) +
  guides(colour = guide_legend(title = "Forecast"))
```

Conclusion of section 5.2

## 5.3 Fitted values and residuals

Each observation in a time series can be forecast using all previous observations. We call these <b>fitted values</b> and they are denoted by , meaning the forecast of yt based on observations y1,…,yt−1 . We use these so often, we sometimes drop part of the subscript and just write ^yt instead of ^yt|t−1. Fitted values almost always involve one-step forecasts.

For example, if we use the mean method, the fitted values are given by $$\hat{y_t} = \hat{c}$$

When the estimate of c involves observations after time t, the fitted values are not true forecasts. On the other hand, naïve or seasonal naïve forecasts do not involve any parameters, and so fitted values are true forecasts in such cases.

## Residuals

The “residuals” in a time series model are what is left over after fitting a model. The residuals are equal to the difference between the observations and the corresponding fitted values:

$$e_t = y_t - \hat{y_t}$$

The fitted values and residuals from a model can be obtained using the `augment()` function. In the beer production example in Section 5.2, we saved the fitted models as `beer_fit`. So we can simply apply `augment()` to this object to compute the fitted values and residuals for all models.

```{r}
augment(beer_fit)
```

There are three new columns added to the original data:

•    `.fitted` contains the fitted values;
•    `.resid` contains the residuals;
•    `.innov` contains the “innovation residuals” which, in this case, are identical to the regular residuals.

## 5.4 Residual diagnostics

A good forecasting method will yield innovation residuals with the following properties:

1. The innovation residuals are uncorrelated. If there are correlations between innovation residuals, then there is information left in the residuals which should be used in computing forecasts.
2. The innovation residuals have zero mean. If they have a mean other than zero, then the forecasts are biased.

If either of these properties is not satisfied, then the forecasting method can be modified to give better forecasts. Adjusting for bias is easy: if the residuals have mean m, then simply subtract m from all forecasts and the bias problem is solved. Fixing the correlation problem is harder, and we will not address it until Chapter 10.

3. The innovation residuals have constant variance. This is known as “homoscedasticity”.
4. The innovation residuals are normally distributed.

```{r Figure 5.9: Daily Google stock prices in 2015.}
google_stock <- gafa_stock %>%
  filter(Symbol == "GOOG", year(Date) >= 2015) %>%
  mutate(day = row_number()) %>%
  update_tsibble(index = day, regular = TRUE)

google_2015 <- google_stock %>% filter(year(Date) == 2015)
autoplot(google_2015, Close) +
  labs(y = "$US",
       title = "Google daily closing stock prices in 2015")
```

The residuals obtained from forecasting this series using the naïve method are shown in Figure 5.10. The large positive residual is a result of the unexpected price jump in July.

```{r Figure 5.10: Residuals from forecasting the Google stock price using the naïve method.}

aug <- google_2015 %>% 
  model(NAIVE(Close)) %>% 
  augment()
autoplot(aug, .innov) +
  labs(y = "$US",
       title = "Residuals from the naïve method")

```

```{r Figure 5.11: Histogram of the residuals from the naïve method applied to the Google stock price. }
aug %>%
  ggplot(aes(x = .innov)) +
  geom_histogram() +
  labs(title = "Histogram of residuals")
```

```{r Figure 5.12: ACF of the residuals from the naïve method applied to the Google stock price.}

aug %>%
  ACF(.innov) %>%
  autoplot() +
  labs(title = "Residuals from the naïve method")

```

These graphs show that the naïve method produces forecasts that appear to account for all available information. The mean of the residuals is close to zero and there is no significant correlation in the residuals series. The time plot of the residuals shows that the variation of the residuals stays much the same across the historical data, apart from the one outlier, and therefore the residual variance can be treated as constant. This can also be seen on the histogram of the residuals. The histogram suggests that the residuals may not be normal — the right tail seems a little too long, even when we ignore the outlier. Consequently, forecasts from this method will probably be quite good, but prediction intervals that are computed assuming a normal distribution may be inaccurate.

A convenient shortcut for producing these residual diagnostic graphs is the gg_tsresiduals() function, which will produce a time plot, ACF plot and histogram of the residuals.

```{r Figure 5.13: Residual diagnostic graphs for the naïve method applied to the Google stock price.}

google_2015 %>% 
  model(NAIVE(Close)) %>% 
  gg_tsresiduals()

```

## Portmanteau tests for autocorrelation

In addition to looking at the ACF plot, we can also do a more formal test for autocorrelation by considering a whole set of rk values as a group, rather than treating each one separately.

the <b>Ljun-Box test</b>, based on

$$Q^*=T(T+2)\sum_{k=1}^\ell(T-k)^{-1}r^2_k$$

For the Google stock price example, the naïve method has no parameters, so K=0 in that case also. In the following code, lag=ℓ and dof=K.

```{r}

aug %>% features(.innov, box_pierce, lag = 10, dof = 0)

aug %>% features(.innov, ljung_box, lag = 10, dof = 0)

```

For both Q and Q∗, the results are not significant (i.e., the p-values are relatively large). Thus, we can conclude that the residuals are not distinguishable from a white noise series.

An alternative simple approach that may be appropriate for forecasting the Google daily closing stock price is the drift method. The `tidy()` function shows the one estimated parameter, the drift coefficient, measuring the average daily change observed in the historical data.

```{r}
fit <- google_2015 %>% model(RW(Close ~ drift()))
tidy(fit)
```

Applying the Ljung-Box test, we set K=1 to account for the estimated parameter.

```{r}
augment(fit) %>% features(.innov, ljung_box, lag = 10, dof = 1)

```

As with the naïve method, the residuals from the drift method are indistinguishable from a white noise series.

Conclusion of section 5.4